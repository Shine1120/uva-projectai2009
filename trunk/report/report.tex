\documentclass[11pt,twocolumn]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{color}
\usepackage{epsfig}
\usepackage{float}
\usepackage{algorithm}
\usepackage[noend]{algorithmic} 
\usepackage{float} 
\setlength\topmargin{-0.5in}
\setlength\headsep{0in}
\setlength\textheight{9.5in}
\definecolor{gray}{rgb}{0.9,0.9,0.9}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\tbf}{\textbf}
\newcommand{\tit}{\textit}
\newcommand{\ds}{\displaystyle}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

%GOOD FOR POSITIONING THE IMAGES AND THE TABLES WELL??????????
\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}   
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}
%?????????????????????????????????????????????????????????????

\title{\tbf{Dirty Money:}\\\tbf{Feature selection using AdaBoost}}
\author{J. van Turnhout (0312649) jturnhou@science.uva.nl, 
	 \\ N. Raiman (0336696) nraiman@science.uva.nl, 
	 \\ S. L. Pintea (6109969) s.l.pintea@student.uva.nl}

\begin{document}
	\maketitle
	
	\begin{abstract}
		In the month January of 2010 a project on the classification of
		the fitness of money was proposed. During this month we have tested and
		implemented various techniques to handle the problem of money classification.
		The results from our experiment show promising development comparing to the
		current state of research.
		
		In the below sections we have described the approaches that we
		have tried and the results obtained for each one of them.
	\end{abstract}
	
	\section{Introduction}
		The goal of this project is to research several techniques that have a potential to distinguish between clean bills and dirty bills. In order to achieve this goal we had to think of what are the representative features of dirt that can be found on money bills and what techniques can be applied to model this.
		 		
		The main techniques used in this project are: \emph{PCA}, \emph{Haar-like features}, \emph{Convolution with predefined kernels}, \todo{\emph{edge-detection} and \emph{intensity} distributions}. All of these techniques have been analysed on the image data using a machine learning technique called Adaptive Boosting, also refered to in literature as AdaBoost.
		
		In section \ref{sec:Background}, related work on the project is discussed. In section \ref{sec:Methods}	\emph{Haar-like features}, \emph{convolution with kernels}, \emph{PCA}, \emph{SVM}, \emph{AdaBoost}, \emph{edge detection} and \emph{intensity} are discussed. The implementation of the \emph{AdaBoost} algorithm applied on the different techniques is explained in \ref{sec:implementation}. We discuss our	experiments and their results in section \ref{sec:results}. Finally, we conclude in section \ref{sec:conclusion} and propose some topics for future research.
		
		\todo{what about telling first about what is done in previous projects. Then
		tell the idea of implementing a few techiniques to extract weak classifiers
		on regions of the bills and then combine them using Adaboost. So first we
		talk about previous work, then explain Adaboost and then talk about PCA,
		HaarConv and Intens\&Edge}
	
	\section{Background}\label{sec:Background}
		In Europe a lot of different factories produce euro bills using different ink and paper. This makes the task of detecting dirty bills hard because looking at the global features will not work perfectly due to these small differences in printing. In Holland, on average bills return 2 to 3 times a year to the Dutch National Bank (DNB) with a total value of 1.1 bilion bills a year. 

		The current approach used in the DNB is to measure the reflection of the bill on a small area near the water mark. With this approach 30\% of all bills are destroyed in order to destroy 95\% of the dirty bills. In a first attempt to make this selection process more		sophisticated global features (eigen-money) of clean and dirty bills are extracted using PCA analysis \todo{cite:MoNuSt}. This approach improved on the results of the current method used by the DNB. \todo{cite:Geusebroek} improved this implementation by learning more local features of the water mark region (also refered to as white patch) of the bill. This approach again improved the current results from DNB.
		
		\hspace*{10px}\todo{We think these results can be improved by learning weak
		classifeirs on small areas (i.e. learn more local patterns) and combine those
		to a strong classifier using Adaboost. The methods used and experiments done
		are explained in the remainder of this deliverable}
	
	\section{Methods}\label{sec:Methods}
		\subsection{Adaboost}\label{sec:Adaboost}
			The \emph{AdaBoost} algorithm can be used in combination with different techniques throughout this project, such as: \emph{PCA}, \emph{Haar-like features} or \emph{edge} and \emph{intensity} distributions over different regions.
			
			AdaBoost is a machine learning technique which can be used in conjunction with various other learning algorithms. The idea is to have a (convex) set of weak classifiers (classifiers that perform at least better than random) and then minimize the total error over the training-set by finding the best classifier at each stage of the algorithm.

			The theoretical basis of this algorithm is that given a set of models (or features), \emph{M}, the algorithm will determine the subset of \emph{T} models that	 are the best for distinguishing between the two classes (clean and dirty bills). Thus, \emph{AdaBoost} will learn the most representative features of the two classes. The algorithm for determining the best models is shown in section \ref{sec:implementation}: \emph{Algorithm~\ref{AdaBoost}}.
			
			Another very important characteristic of this algorithm is the fact that it also specifies a method in which the models that were chosen as being the best, can be combined in order to give a strong classifier. The corresponding algorithm can be seen in section \ref{sec:implementation}: \emph{Algorithm~\ref{AdaBoost_pred}}.
			
			\todo{In our approach we split the bill in small regions (i.e. dividing the bill in 5 by 12 regions). For each region we train a weak classifier and those are combined into a strong classifier using \emph{AdaBoost}}
			 
		\subsection{Haar-like features and Convolution over kernels}\label{sec:Haar}
			The first idea that we have tried was to implement the \emph{Viola \& Jones} approach for object detection. The final cascade used in this paper was not implemented because the main idea of this cascade was not suitable for the purpose of this project. We have used the strong classifier computed in \emph{AdaBoost} as the final output.
			
			\begin{figure}[!hbtp]
				\fbox{\epsfig{file=img/patterns.eps, width=0.9\linewidth} }	
				\caption{Patterns}
				\label{patterns}
			\end{figure}
			
			The first step of the algorithm is defining the patterns, that
			are mainly matrixes of different dimensions containing low and high values
			for intensity (-1 and 1) -- Figure\ref{patterns} indicates a subset of the
			patterns used. The algorithm used in the \emph{Viola \& Jones} article was
			designed to loop over all predefined patterns on each position in the image
			and convolve the specific region of the image with the patterns using the
			formula depicted in Figure\ref{patterns_formula}.\\
			\begin{figure}
				\fontfamily{ccr}\selectfont\small
				\caption{}
				\begin{tabular}{|lr|} \hline
					& \\[5pt]
					\textcolor{blue}{$\sum_x\sum_y Image(y:y+h,x:x+w) .* Pattern$} &\\[10pt]
					where: \emph{h} -- the heigh of the pattern &\\
					\hspace*{28px} \emph{w} -- the width of the pattern &\\[5pt] 
					\hline 
				\end{tabular}
				\label{patterns_formula}
			\end{figure}
			\hspace*{10px}We have started by defining a large number of patterns of
			different sizes ($\approx$100 patterns), and we have filtered out those that
			gave bad results when used in the \emph{AdaBoost algorithm} for training the
			weak classifiers. The resulted values for each pattern and location in the
			image would, then, be used in \emph{AdaBoost} to train an \emph{SVM}
			classifier.\\ 
			\hspace*{10px}Taking into account the fact that the set of features generated
			by the algorithm for each pattern and each image, was extremely large, and
			the training took too much time. In order to solve this problem, we have
			decided to use just random locations at which to convolve the patterns with a
			region of the image (that would have the same size with the pattern).
			Figure~\ref{Haar_features} indicates what \emph{AdaBoost} would choose as
			being the most representative 5 features for the front side and rear side of
			the bills.\\ 
			\begin{figure}[!hbtp]
				\centering
				\epsfig{file=img/haar.eps, width=1\linewidth}
				\caption{Haar Features for Front and Rear}
				\label{Haar_features}
			\end{figure}
			\hspace*{10px}The results obtained using \emph{Haar features} were not as
			good as we would have expected them to be. An explanation for this may be the
			fact that the patterns defined were not entirely able to model the dirt that
			can be found on the bills.\\ 
			\hspace*{10px}The second approach that we have tried was to define a set of
			patterns as before, and to segment each image into smaller regions that would
			be, then, convolved with the patterns.\\ 
			\hspace*{10px}We have tried using both no-overlapping segmentation of the
			images and 50\% overlapping one. Due to the fact that many essential pixel
			values (like those that would indicate the presence of dirt) may happen to be
			positioned on the line that separates two neighboring regions, is possible
			that some information will be lost. Taking into account the number of regions
			generated for all images we can notice that there is a large amount of pixel
			values that might not be considered in the case of no-overlapping
			segmentation. As expected, the second method of dividing the images into
			regions gave better results compared to the first one.\\ 
			\hspace*{10px}The results obtained using this technique represented the input
			set of features for the \emph{AdaBoost algorithm}. Figure~\ref{convolved}
			will help getting a better understanding of how the convolved regions of
			image and patterns would look like. In this image it is plotted the result
			obtained when convolving a bill with a simple pattern such as: \textbf{[1
			-1;-1 1]} with an entire bill.\\ 
			\begin{figure}[!hbtp]
				\centering
				\epsfig{file=img/convolution.eps, width=1\linewidth}
				\caption{Convolution of an entire bill}
				\label{convolved}
			\end{figure} 
			Thus, the resulted set of models would represent the input features used in
			\emph{AdaBoost}. For establishing the set of the best \emph{T} features we
			have tried using both \emph{SVM} and \emph{Gaussian distribution}, and the
			results retrieved by the last one seemed slightly better than the ones
			obtained while using \emph{SVM}. In the case in which \emph{SVM} was used, a
			model was generated for each available feature. This model would give the
			best separation between the values corresponding to that feature for fit
			images and those for unfit images. In the case of the \emph{Gaussian
			distribution}, the mean and covariance of features corresponding to fit
			images were computed, respectively the mean and covariance for the features
			corresponding to unfit images. In order to determine the predicted class of
			the input images we have tried two methods.\\ 
			\hspace*{10px}In the first method we would simply compute the \emph{mean} and
			\emph{covariance} for the values corresponding to fit, respectively unfit
			values corresponding to a specific feature. During testing, for each input
			value, we would compare the two numbers returned by \emph{Gaussian density
			function} for fit, respectively unfit and we would choose the predicted class
			to be the maximum of the two.\\ 
			\hspace*{10px}The second method was using \emph{Naive Bayes} in order to make
			use of the prior knowledge available. We know that in a real-life situation
			there are always more fit bills than unfit one and we would like to use this
			information to improve our classifiers. The predicted class was defined by
			using the \emph{MAP} (maximum aposterior probability) estimation. The formula
			for computing the maximum aposterior probability for fit, respectively unfit
			class is given by the formulas depicted in Figure\ref{MAP_formula}.\\
			\begin{figure}[!hbtp] \fontfamily{ccr}\selectfont\small
				\caption{}
				\begin{tabular}{|lr|} \hline
					&\\[5pt]
					\textcolor{blue}{$argmax_{\theta_{fit}}P(\theta_{fit}\mid X) = $} &\\[5pt]
					\hspace*{50px}\textcolor{blue}{$\frac{P(\theta_{fit})*P(X\mid \theta_{fit})}{P(\theta_{fit})*P(X\mid \theta_{fit}) + P(\theta_{unfit})*P(X\mid \theta_{unfit})}$} &\\[15pt]
					\textcolor{blue}{$argmax_{\theta_{unfit}}P(\theta_{unfit}\mid X) = $} &\\[5pt]
					\hspace*{50px}\textcolor{blue}{$\frac{P(\theta_{unfit})*P(X\mid \theta_{unfit})}{P(\theta_{fit})*P(X\mid \theta_{fit}) + P(\theta_{unfit})*P(X\mid \theta_{unfit})}$} &\\[10pt]
			\hline
			\end{tabular}
					where: 
					\begin{itemize}
					\item $P(\theta_{fit}), P(\theta_{unfit})$ -- marginal probabilities of
						"fit" class, respectively "unfit" class
					\item $\theta_{fit}, \theta_{unfit}$ -- the parameters of the classes (mean
						and covariance)
					\item $P(X\mid \theta_{fit}),P(X\mid \theta_{unfit})$ -- the conditional
						probabilities of the two classes (representing normal distributions)
					\end{itemize} 
			\label{MAP_formula}
			\end{figure}
			It can be easily shown that the values of the parameters $\theta$ for a
			normal distribution (mean and covariance) that would maximize the probability
			of the classes are exactly the corresponding formulas indicated in
			Figure\ref{mu_sigma}.\\ 
			\emph{ \begin{figure}[!hbtp] \fontfamily{ccr}\selectfont\small
				\caption{}
				\begin{tabular}{|lr|} \hline
						&\\[5pt]	
						\textcolor{blue}{$\mu$ = $\sum_i \frac{x_i}{\mid X \mid}$}&\\
						\textcolor{blue}{$\sigma$ = $\frac{(X - \mu)(X - \mu)^T}{\mid X \mid}$} &\\[10pt]  
						where X -- the training data set &\\
						\hspace*{28px} $\mu$ -- the mean &\\
						\hspace*{28px} $\sigma$ -- the covariance &\\[5pt]
				\hline
				\end{tabular}
				\label{mu_sigma}
			\end{figure}
			}
			The second technique used for determining the predicted class of the data
			given the parameters seemed to provides slightly better results in practice
			due to the fact that it also incorporates some prior knowledge of the data.\\
			\hspace*{10px}For this approach we have used two classifiers: one for the
			rear side and another for the front side of the bills and the predictions
			given by the two classifiers were combined into a third one using Naive
			Bayes.\\ 
			\hspace*{10px}In order to create the final model, we have tried two different
			methods:
			\begin{itemize}
				\item the first one was essentially just choosing the best model (the one
				that gives the minimum error) throughout all the repetitions and all the
				rounds in the cross-validation;
				\item the second method was to use a system of voting -- each time a
				feature was chosen by the \emph{AdaBoost} algorithm, it would receive a
				vote. In the end the top \emph{T} most voted features throughout all the
				cross-validation rounds and all the repetitions would be chosen from the
				best model found. The corresponding weights would be generate by taking the
				mean of the features\rq\@ $\alpha$-weights computed in the \emph{AdaBoost}
				algorithm;
			\end{itemize}
			As we would have expected, the second method for defining the best model,
			proved to give better results in this case so it was chosen to be applied.
		
		\subsection{PCA and SVM}\label{sec:PCA}
			\hspace*{10px}In previous research, the use of SVM in combination with PCA already gave great error reduction on both the 5 and 10 euro bills. These results were conducted from performing PCA on the whitepatch area only, and propagate the projections in SVM. PCA on the whitepatch as well as the whole bill made it possible to reduce the data from a dimensionality equal to the number of pixels of the respective area to only a 30 components. This reduction ensures faster training and classification with SVM. The idea in this project is to identify more regions with similar discriminative features as the whitepatch. This is done by dividing the bill up in an arbitrary number of regions, and performing PCA for each of these regions in all the bills. The PCA segments then can be used to train SVM models for each segment. These SVM models in combination with their respective PCA segments in turn can be used as weak classifiers in AdaBoost.

		\subsection{Intensity and Edge distributions}\label{sec:Intensity_Edge}
			\hspace*{10px}Besides the more complex approaches we desided to implement
			also two more simple implementations, based on the intensities on the image
			and on the edges on the bill. The idea of using the intensity is based on
			the current approach used in the DNB (e.g. measureing the reflection of
			light on a small patch near the watermark \todo{see section background}).
			The idea of using the edges is based on the assumption that dirty and old
			bills have significantly more wrinkels and folds then relative new bills. In
			the first simple implementation the \todo{raw} intensity of the image of the
			bill is used. Herefor the bills are segmented in small regions (5 by 12)
			(\todo{see figure ??}). Over these regions the average intensity is
			calculated. In this way it is possible to retrieve two gaussian distributions
			of the intensity of all the regions over all the images, one for clean bills
			and one for dirty bills. This provides a tool to compare the probability
			of a region on a bill belonging to a clean or dirty bill.
			In the edge approach the image is first filtered using the canny-edge
			detector. The canny edge filter works in 5 steps: 
			\begin{itemize} 
				\item Step 1: gaussian smoothing 
				\item Step 2: extract the gradient of the image by convolving the image
						with 2 kernels, one to find the derivative in the X direction and one to
						find the derivative in the Y direction				
				\item Step 3: determin the direction of the edge using results from step 2  
				\item Step 4: apply nonmaximum suppression to find the real edge (selecting
						only the maximum edge points found)
				\item Step 5: finally the \todo{hysterisis} is used to make the lines
						continues
            \end{itemize} 
            The result of an image of a bill after applying canny edge filter
            can be seen in figure \ref{canny5Euro}.
            \begin{figure}[!hbtp]
				\centering 
				\epsfig{file=img/canny5euro.eps, width=1\linewidth}
				\caption{results canny edge filter. Left on a clean bill. Right on a dirty
				bill} 
				\label{canny5Euro} 
			\end{figure} 
			After applying the canny edge filter to the images the resulting images are
			segmented in small regions. Per region the sum of edge points is calculated.
			When doing this for all images we can again extract two gaussian
			distributions of edge points per region (one for clean and one for dirty
			bills).

	\section{Implementation}\label{sec:implementation}
		\begin{algorithm}[!hbtp]
			\caption{AdaBoost learning features}
			\label{AdaBoost}
			\begin{algorithmic}[1]
			\medskip
			\STATE \tbf{function} AdaBoostLearn($T$, $M$, $S$) 
			\STATE {$T$ = nr. of hypothesis}
			\STATE {$M$ = Models}
			\STATE {$S$ = training-set, \{$(x_1,y_1),...(x_n,y_n)$\} \\ with $x_i \epsilon X$ and $y_i \epsilon \{-1, 1\}$ }
			\STATE {$D_{1(i)} \leftarrow \frac{1}{n}$, with $i=1,...,n$}
			\FOR {$t=1$ to $T$}
				\STATE {$error_t \leftarrow 0$}
				\FOR {$m \epsilon M$}
					\STATE {$h_j(x_i) \leftarrow predict(x_i)$ \%\tit{svm or gaussian distribution}}
					\STATE {$error_j \leftarrow \sum^n_{i=1}D_t(i)[y_i \neq h_j(x_i)]$}
					\IF {$error_j < error_t$}
						\STATE {$error_t \leftarrow error_j$}
						\STATE {$h_t \leftarrow h_j$}
					\ENDIF
				\ENDFOR
				\STATE {$\alpha_t \leftarrow 0.5 \cdot \log{\frac{1-error_t}{error_t}}$}
				\FOR {$i=1$ to $n$}
					\STATE {$D_{t+1}(i) \leftarrow \frac{D_t(i)\exp{-\alpha_t \cdot y_i \cdot h_t(x_i)}}{Z_t}$}
				\ENDFOR
			\ENDFOR
			\STATE {\tbf{return} $\alpha, h$}
			\end{algorithmic}
			\label{alg:AdaBoostLearn}
		\end{algorithm}
		\begin{algorithm}[!hbtp]
			\caption{AdaBoost Prediction}
			\label{AdaBoost_pred}
			\begin{algorithmic}[1]
			\medskip
			\STATE \tbf{function} AdaBoostPredict($\alpha$, $h$, $I$)
			\STATE { $\alpha$ = weights }
			\STATE { $h$ = weak classifiers}
			\STATE {$I$ = image}
			\STATE {$p$ = prediction} 
			\FOR {$t=1$ to $length(\alpha)$}
				\STATE $p \leftarrow p + \alpha_th_t(I)$
			\ENDFOR
			\STATE {\tbf{return} $sign(p)$}
			\end{algorithmic}
			\label{alg:AdaBoostPredict}
		\end{algorithm}

	\section{Results}\label{sec:results}
		\hspace*{10px}The available image set was spilt into a holdout set and the
		rest of the data was again split into a validation set and a part that was
		used for training the final model by \emph{random sub-sampling
		cross-validation} technique. The whole process of defining the validation set
		and applying random sub-sampling cross-validation was repeated several times
		to ensure a correct estimation of the predictions. For each round of the
		cross-validation, a model was trained using the \emph{AdaBoost algorithm}
		described above. The obtained model was, then, tested by building the strong
		classifier and computing the corresponding values for: \emph{true-positive
		estimation}, \emph{true-negative estimation}, \emph{false-positive estimation}
		and \emph{false-negative estimation}.\\
		\subsection{Convolution Results}\label{sec:haar_results}
		\hspace*{10px}Due to the fact that the number of features generated for only
		21 patterns and a segmentation for each image of 23 overlapping regions by 9
		gives 4,347 features, the training part is relatively slow for this method. In
		order to create reliable model we have used 5 repetitions, 10 hypothesis
		(features to be chosen by AdaBoost), 10 trials in the random sampling
		cross-validation method.\\ \hspace*{10px}In Figure\ref{haar_regions10} are
		indicated the most voted regions for the 10 Euro bills in \emph{AdaBoost}
		throughout all trials and all repetitions. We can notice that for the front of
		the bills the regions selected are mainly positions on the water mark area,
		while for the rear side of the bills, there are some regions considered as
		being the most informative on the white patch, but also the area in the middle
		is selected as containing discriminative information.\\ 
		\begin{figure}[!hbtp]
			\centering
			\epsfig{file=img/haar_regions10.eps, width=1\linewidth}
			\caption{Best regions for 10 Euro bills}
			\label{haar_regions10}
		\end{figure}
		\hspace*{10px}Figure\ref{haar_regions5} shows the most voted regions for the 5
		Euro bills in \emph{AdaBoost} throughout all trials and all repetitions. For
		the 5 Euro bills the regions for front and rear that were chosen as being the
		most informative ones are again mainly around the water mark area, but unlike
		those for 10 Euro Bills, the regions for front side are the ones that are more
		spread throughout the image.\\ 
		\begin{figure}[!hbtp]
			\centering
			\epsfig{file=img/haar_regions5.eps, width=1\linewidth}
			\caption{Best regions for 5 Euro bills}
			\label{haar_regions5}
		\end{figure} 
		\hspace*{10px}In order to determine the optimal number of features that should
		be chosen in the end for the best model, we have plotted the error with
		respect to the number of features chosen. Figure\ref{haar_plot10} and
		Figure\ref{haar_plot5} show how the error evolves depending on the number of
		models for the 10 Euro bills, respectively for the 5 Euro bills. 
		\begin{figure}[!hbtp]
			\centering
			\epsfig{file=img/haar_plot10.eps, width=1\linewidth}
			\caption{Error depending on the number of features - 10 Euro bills}
			\label{haar_plot10}
		\end{figure} 
		\begin{figure}[!hbtp]
			\centering
			\epsfig{file=img/haar_plot5.eps, width=1\linewidth}
			\caption{Error depending on the number of features - 5 Euro bills}
			\label{haar_plot5}
		\end{figure} 
	
		\subsection{PCA Results}\label{sec:pca_results}
			\todo{RESULTS PCA}
	
		\subsection{Intensity \& Edges Results}\label{sec:ie_results}
			\todo{RESULTS IE}
	
		\subsection{Combined Results}\label{sec:comb_results}
			\hspace*{10px}Once all the strong classifiers for each of the methods above
			has been generated, we have combined their predictions using \emph{Naive
			Bayes}.\\ 
			\hspace*{10px}The results for 10 Euro bills, respectively 5 Euro bills are
			shown in the Table\ref{table10} and Table\ref{table5}. 
			\begin{table}[!htbp]
				\caption{Results for 10 Euro bills}
				\fontfamily{ccr}\selectfont\small
				\label{table10}
				\centering 
				\begin{tabular}{ | c | c | c|}
					\hline\hline & \emph{Fit Error} & \emph{Unfit Error} \\ [0.5ex]\hline 
					\emph{Haar} & 0.05 & 0.15 \\ [0.5ex]\hline
					\emph{IE} & 0.1 & 0.025 \\ [0.5ex]\hline
					\emph{PCA} & 0.083 & 0.05 \\ [0.5ex]\hline
					\emph{Haar \& IE} & 0.033 & 0.15 \\ [0.5ex]\hline
					\emph{Haar \& PCA} & 0.017 & 0.2 \\ [0.5ex]\hline
					\emph{IE \& PCA} & 0.017 & 0.075 \\ [0.5ex]\hline
					\emph{Haar \& IE \& PCA} & 0.033 & 0.025 \\ [0.5ex]\hline
				\end{tabular} 
				\label{table:nonlin10eur} 
			\end{table}		
			\begin{table}[!htbp]
				\caption{Results for 5 Euro bills}
				\fontfamily{ccr}\selectfont\small
				\label{table5}
				\centering 
				\begin{tabular}{ | c | c | c|}
					\hline\hline & \emph{Fit Error} & \emph{Unfit Error} \\ [0.5ex]\hline 
					\emph{Haar} & 0 & 0 \\ [0.5ex]\hline
					\emph{IE} & 0.033 & 0 \\ [0.5ex]\hline
					\emph{PCA} & 0.083 & 0.025 \\ [0.5ex]\hline
					\emph{Haar \& IE} & 0 & 0 \\ [0.5ex]\hline
					\emph{Haar \& PCA} & 0 & 0.025 \\ [0.5ex]\hline
					\emph{IE \& PCA} & 0.033 & 0.025 \\ [0.5ex]\hline
					\emph{Haar \& IE \& PCA} & 0.033 & 0 \\ [0.5ex]\hline
				\end{tabular}
				\label{table:nonlin5eur} 
			\end{table}


	\section{Conclusion}\label{sec:conclusion}
		\hspace*{10px}From our experiments we have been able to learn the regions
		that contain the largest amount of information and help us distinguish
		between fit and unfit bills. These regions differ from one method to another,
		but in general the areas around the water-mark region and the middle of the
		bills have been proven to be the ones containing the most discriminative
		features.\\ 
		\hspace*{10px}As it can be noticed from the results in
		Section\ref{sec:comb_results}, combining different techniques leads to an
		improvement in the performance of the final classifier.\\
		\hspace*{10px}Although the results obtained using these 3 methods are as good
		as we would have expected them to be, future work is possible and it should
		be mainly focused on finding a more powerful way of combining all the
		features used by all 3 techniques (Haar, PCA, Intensity \& Edge) into a
		strong classifier.\\ \hspace*{10px}We would also recommend that special
		attention should be payed to the validity of certain features of the images
		from the data set (intensity).\\
		
		\todo{EDGE::  future work: Finding the intensity gradient of the image in
		stead of just canny edge detection and Non-maximum suppression\\
		the first step of canny edge detection is to apply gaussian smoothing on the
		image. If the kernel used is too big and the borders are smoothed using zero
		padding this can eliminate very important data from the borders, which could
		hold very important distictive features for classifying clean and dirty/used
		bills.}
		
		\bibliographystyle{alpha} 
		\begin{thebibliography}{3} 
			\bibitem{Haar}
				P. Viola \& M. Jones:\\
				\tit{Rapid Object Detection using a Boosted Cascade of Simple Features}
				(CVPR 2001)
			\bibitem{Ada}
				AdaBoost: \\
				\tit{http://en.wikipedia.org/wiki/AdaBoost}	
			\bibitem{MoNuSt}Eigen money approach: \\
				\tit{Molenaar, Nusselder and Stefanov}	
		\end{thebibliography}
\end{document}