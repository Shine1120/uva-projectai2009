\documentclass[11pt,twocolumn]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{color}
\usepackage{epsfig}
\usepackage{float}
\usepackage{algorithm}
\usepackage[noend]{algorithmic} 
\usepackage{float} 
\setlength\topmargin{-0.5in}
\setlength\headsep{0in}
\setlength\textheight{9.5in}
\definecolor{gray}{rgb}{0.9,0.9,0.9}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\tbf}{\textbf}
\newcommand{\tit}{\textit}
\newcommand{\ds}{\displaystyle}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

%GOOD FOR POSITIONING THE IMAGES AND THE TABLES WELL??????????
\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}   
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}
%?????????????????????????????????????????????????????????????

\title{\tbf{Dirty Money:}\\\tbf{Feature selection using AdaBoost}}
\author{J. van Turnhout (0312649) jturnhou@science.uva.nl, \\ N. Raiman (0336696) nraiman@science.uva.nl, \\ S. L. Pintea (6109969) s.l.pintea@student.uva.nl}

\begin{document}
	\maketitle
	\begin{abstract}
		\hspace*{10px}In the month January of 2010 a project on the classification of
		the fitness of money was proposed. During this month we have tested and
		implemented various techniques to handle the problem of money classification.
		The results from our experiment show promising development comparing to the
		current state of research.\\ 
		\hspace*{10px}In the below sections we have described the approaches that we
		have tried and the results obtained for each one of them.
	\end{abstract}

	\section{Introduction}
		\hspace*{10px}The goal of this project is to determine a reliable method that
		would be able to distinguish between dirty bills and clean bills. In order to
		achieve this goal we had to think of what are the representative features of
		dirt that can be found on money bills and what is the best method that can be
		used to model this.\\  
		\hspace*{10px}Throughout this project we have tried a number of different
		approaches in order to gain good results and in the same time we have tried
		to get a better understanding of what methods are fit for describing the
		features of the dirty money and clean money.\\ 
		\hspace*{10px}The main techniques used in this project are: \emph{PCA} in
		combination with \emph{AdaBoost}, \emph{Haar-like features} and
		\emph{Adaboost}, \emph{Convolution with predefined kernels},
		\todo{\emph{edge-detection} and \emph{intensity} distributions}.\\ 
		\hspace*{10px}In section \ref{sec:background}, related work on
		\emph{Haar-like features}, \emph{convolution with kernels}, \emph{PCA},
		\emph{SVM}, \emph{AdaBoost}, \emph{edge detection} and \emph{intensity} are
		discussed. The implementation of the \emph{AdaBoost} algorithm applied on the
		different techniques is explained in \ref{sec:implementation}. We discuss our
		experiments and their results in section \ref{sec:results}. Finally, we
		conclude in section \ref{sec:conclusion} and propose some topics for future
		research.\\ 
		\todo{what about telling first about what is done in previous projects. Then
		tell the idea of implementing a few techiniques to extract weak classifiers
		on regions of the bills and then combine them using Adaboost. So first we
		talk about previous work, then explain Adaboost and then talk about PCA,
		HaarConv and Intens\&Edge}
	
	\section{Background}\label{sec:background}
		\todo{something about the current state and previous projects}
	
	\section{Methods}\label{sec:Methods}
		\todo{are we going to tell something about the current approach of DNB and the
		previous projects we build on?}\\
		\hspace*{10px}Finding the main features of dirty money and clean money was a
		true challenge in this project. In this section are indicated in more detail
		the ups and downs of the techniques used and the theoretical knowledge that
		represents the basis of these methods.
	
	\subsection{Adaboost}\label{sec:Adaboost}
		\hspace*{10px}The \emph{AdaBoost} algorithm is used in combination with
		different techniques throughout this project, such as: \emph{PCA},
		\emph{Haar-like features} or \emph{edge} and \emph{intensity} distributions
		over different regions.\\ \hspace*{10px}Adaptive Boosting (also known as
		AdaBoost) is a machine learning technique which can be used in conjunction
		with various other learning algorithms. The idea is to have a (convex) set of
		weak classifiers (classifiers that perform at least better than random) and
		then minimize the total error over the training-set by finding the best
		classifier at each stage of the algorithm.\\ 
		\hspace*{10px}The theoretical basis of this algorithm is that given a set of
		models (or features), \emph{M}, the algorithm will determine the subset of
		\emph{T} models that are the best for distinguishing between the two classes
		(clean and dirty bills). Thus, \emph{AdaBoost} will learn the most
		representative features of the two classes. The algorithm for determining the
		best models is shown in section \ref{sec:implementation}:
		\emph{Algorithm~\ref{AdaBoost}}.\\ 
		\hspace*{10px}Another very important characteristic of this algorithm is the
		fact that it also specifies a method in which the models that were chosen as
		being the best, can be combined in order to give a strong classifier. The
		corresponding algorithm can be seen in section \ref{sec:implementation}:
		\emph{Algorithm~\ref{AdaBoost_pred}}.\\
		 
	\subsection{PCA}\label{sec:PCA}
		\todo{\hspace*{10px}PCA !!!}
				
	\subsection{Haar-like features and Convolution over kernels}\label{sec:Haar}
	\hspace*{10px}The first idea that we have tried was to implement the
	\emph{Viola \& Jones} approach for object detection. The final cascade used in
	this paper was not implemented because the main idea of this cascade was not
	suitable for the purpose of this project. We have used the strong classifier
	computed in \emph{AdaBoost} as the final output.\\ 
	\begin{figure}[!hbtp]
		\fbox{\epsfig{file=img/patterns.eps, width=0.9\linewidth} }	
		\caption{Patterns}
		\label{patterns}
	\end{figure}
	\hspace*{10px}The first step of the algorithm is defining the patterns, that
	are mainly matrixes of different dimensions containing low and high values
	for intensity (-1 and 1) -- Figure\ref{patterns} indicates a subset of the
	patterns used. The algorithm used in the \emph{Viola \& Jones} article was
	designed to loop over all predefined patterns on each position in the image
	and convolve the specific region of the image with the patterns using the
	formula depicted in Figure\ref{patterns_formula}.\\
	\begin{figure}
		\fontfamily{ccr}\selectfont\small
		\caption{}
		\begin{tabular}{|lr|} \hline
			& \\[5pt]
			\textcolor{blue}{$\sum_x\sum_y Image(y:y+h,x:x+w) .* Pattern$} &\\[10pt]
			where: \emph{h} -- the heigh of the pattern &\\
			\hspace*{28px} \emph{w} -- the width of the pattern &\\[5pt] 
			\hline 
		\end{tabular}
		\label{patterns_formula}
	\end{figure}
\hspace*{10px}We have started by defining a large number of patterns of different sizes ($\approx$100 patterns), and we have filtered out those that gave bad results when used in the \emph{AdaBoost algorithm} for training the weak classifiers. The resulted values for each pattern and location in the image would, then, be used in \emph{AdaBoost} to train an \emph{SVM} classifier.\\
\hspace*{10px}Taking into account the fact that the set of features generated by the algorithm for each pattern and each image, was extremely large, and the training took too much time. In order to solve this problem, we have decided to use just random locations at which to convolve the patterns with a region of the image (that would have the same size with the pattern). Figure~\ref{Haar_features} indicates what \emph{AdaBoost} would choose as being the most representative 5 features for the front side and rear side of the bills.\\
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/haar.eps, width=1\linewidth}
\caption{Haar Features for Front and Rear}
\label{Haar_features}
\end{figure}
	\hspace*{10px}The results obtained using \emph{Haar features} were not as good as we would have expected them to be. An explanation for this may be the fact that the patterns defined were not entirely able to model the dirt that can be found on the bills.\\
	\hspace*{10px}The second approach that we have tried was to define a set of patterns as before, and to segment each image into smaller regions that would be, then, convolved with the patterns.\\
	\hspace*{10px}We have tried using both no-overlapping segmentation of the images and 50\% overlapping one. Due to the fact that many essential pixel values (like those that would indicate the presence of dirt) may happen to be positioned on the line that separates two neighboring regions, is possible that some information will be lost. Taking into account the number of regions generated for all images we can notice that there is a large amount of pixel values that might not be considered in the case of no-overlapping segmentation. As expected, the second method of dividing the images into regions gave better results compared to the first one.\\ 
	\hspace*{10px}The results obtained using this technique represented the input set of features for the \emph{AdaBoost algorithm}. Figure~\ref{convolved} will help getting a better understanding of how the convolved regions of image and patterns would look like. In this image it is plotted the result obtained when convolving a bill with a simple pattern such as: \textbf{[1 -1;-1 1]} with an entire bill.\\
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/convolution.eps, width=1\linewidth}
\caption{Convolution of an entire bill}
\label{convolved}
\end{figure} 
Thus, the resulted set of models would represent the input features used in \emph{AdaBoost}. For establishing the set of the best \emph{T} features we have tried using both \emph{SVM} and \emph{Gaussian distribution}, and the results retrieved by the last one seemed slightly better than the ones obtained while using \emph{SVM}. In the case in which \emph{SVM} was used, a model was generated for each available feature. This model would give the best separation between the values corresponding to that feature for fit images and those for unfit images. In the case of the \emph{Gaussian distribution}, the mean and covariance of features corresponding to fit images were computed, respectively the mean and covariance for the features corresponding to unfit images. In order to determine the predicted class of the input images we have tried two methods.\\
\hspace*{10px}In the first method we would simply compute the \emph{mean} and \emph{covariance} for the values corresponding to fit, respectively unfit values corresponding to a specific feature. During testing, for each input value, we would compare the two numbers returned by \emph{Gaussian density function} for fit, respectively unfit and we would choose the predicted class to be the maximum of the two.\\  
\hspace*{10px}The second method was using \emph{Naive Bayes} in order to make use of the prior knowledge available. We know that in a real-life situation there are always more fit bills than unfit one and we would like to use this information to improve our classifiers. The predicted class was defined by using the \emph{MAP} (maximum aposterior probability) estimation. The formula for computing the maximum aposterior probability for fit, respectively unfit class is given by the formulas depicted in Figure\ref{MAP_formula}.\\
\begin{figure}[!hbtp]
	\fontfamily{ccr}\selectfont\small
	\caption{}
	\begin{tabular}{|lr|} \hline
		&\\[5pt]
		\textcolor{blue}{$argmax_{\theta_{fit}}P(\theta_{fit}\mid X) = $} &\\[5pt]
		\hspace*{50px}\textcolor{blue}{$\frac{P(\theta_{fit})*P(X\mid \theta_{fit})}{P(\theta_{fit})*P(X\mid \theta_{fit}) + P(\theta_{unfit})*P(X\mid \theta_{unfit})}$} &\\[15pt]
		\textcolor{blue}{$argmax_{\theta_{unfit}}P(\theta_{unfit}\mid X) = $} &\\[5pt]
		\hspace*{50px}\textcolor{blue}{$\frac{P(\theta_{unfit})*P(X\mid \theta_{unfit})}{P(\theta_{fit})*P(X\mid \theta_{fit}) + P(\theta_{unfit})*P(X\mid \theta_{unfit})}$} &\\[10pt]
\hline
\end{tabular}
		where: 
		\begin{itemize}
		\item $P(\theta_{fit}), P(\theta_{unfit})$ -- marginal probabilities of "fit" class, respectively "unfit" class 
		\item $\theta_{fit}, \theta_{unfit}$ -- the parameters of the classes (mean and covariance) 
		\item $P(X\mid \theta_{fit}),P(X\mid \theta_{unfit})$ -- the conditional probabilities of the two classes (representing normal distributions) 
		\end{itemize} 
\label{MAP_formula}
\end{figure}
It can be easily shown that the values of the parameters $\theta$ for a normal distribution (mean and covariance) that would maximize the probability of the classes are exactly the corresponding formulas indicated in Figure\ref{mu_sigma}.\\ 
\emph{
\begin{figure}[!hbtp]
\fontfamily{ccr}\selectfont\small
\caption{}
\begin{tabular}{|lr|} \hline
		&\\[5pt]	
		\textcolor{blue}{$\mu$ = $\sum_i \frac{x_i}{\mid X \mid}$}&\\
		\textcolor{blue}{$\sigma$ = $\frac{(X - \mu)(X - \mu)^T}{\mid X \mid}$} &\\[10pt]  
		where X -- the training data set &\\
		\hspace*{28px} $\mu$ -- the mean &\\
		\hspace*{28px} $\sigma$ -- the covariance &\\[5pt]
\hline
\end{tabular}
\label{mu_sigma}
\end{figure}
}
The second technique used for determining the predicted class of the data given the parameters seemed to provides slightly better results in practice due to the fact that it also incorporates some prior knowledge of the data.\\  
 		\hspace*{10px}For this approach we have used two classifiers: one for the rear side and another for the front side of the bills and the predictions given by the two classifiers were combined into a third one using Naive Bayes.\\
		\hspace*{10px}In order to create the final model, we have tried two different methods: 
\begin{itemize}
\item the first one was essentially just choosing the best model (the one that gives the minimum error) throughout all the repetitions and all the rounds in the cross-validation;
\item the second method was to use a system of voting -- each time a feature was chosen by the \emph{AdaBoost} algorithm, it would receive a vote. In the end the top \emph{T} most voted features throughout all the cross-validation rounds and all the repetitions would be chosen from the best model found. The corresponding weights would be generate by taking the mean of the features\rq\@ $\alpha$-weights computed in the \emph{AdaBoost} algorithm;     
\end{itemize}
As we would have expected, the second method for defining the best model, proved to give better results in this case so it was chosen to be applied.
	
	\subsection{Intensity and Edge distributions}\label{sec:Intensity_Edge}
		\todo{\hspace*{10px}Intensity \& Edge!!!}\\

\section{Implementation}\label{sec:implementation}
		\begin{algorithm}[!hbtp]
			\caption{AdaBoost learning features}
			\label{AdaBoost}
			\begin{algorithmic}[1]
			\medskip
			\STATE \tbf{function} AdaBoostLearn($T$, $M$, $S$) 
			\STATE {$T$ = nr. of hypothesis}
			\STATE {$M$ = Models}
			\STATE {$S$ = training-set, \{$(x_1,y_1),...(x_n,y_n)$\} \\ with $x_i \epsilon X$ and $y_i \epsilon \{-1, 1\}$ }
			\STATE {$D_{1(i)} \leftarrow \frac{1}{n}$, with $i=1,...,n$}
			\FOR {$t=1$ to $T$}
				\STATE {$error_t \leftarrow 0$}
				\FOR {$m \epsilon M$}
					\STATE {$h_j(x_i) \leftarrow predict(x_i)$ \%\tit{svm or gaussian distribution}}
					\STATE {$error_j \leftarrow \sum^n_{i=1}D_t(i)[y_i \neq h_j(x_i)]$}
					\IF {$error_j < error_t$}
						\STATE {$error_t \leftarrow error_j$}
						\STATE {$h_t \leftarrow h_j$}
					\ENDIF
				\ENDFOR
				\STATE {$\alpha_t \leftarrow 0.5 \cdot \log{\frac{1-error_t}{error_t}}$}
				\FOR {$i=1$ to $n$}
					\STATE {$D_{t+1}(i) \leftarrow \frac{D_t(i)\exp{-\alpha_t \cdot y_i \cdot h_t(x_i)}}{Z_t}$}
				\ENDFOR
			\ENDFOR
			\STATE {\tbf{return} $\alpha, h$}
			\end{algorithmic}
			\label{alg:AdaBoostLearn}
		\end{algorithm}
		\begin{algorithm}[!hbtp]
			\caption{AdaBoost Prediction}
			\label{AdaBoost_pred}
			\begin{algorithmic}[1]
			\medskip
			\STATE \tbf{function} AdaBoostPredict($\alpha$, $h$, $I$)
			\STATE { $\alpha$ = weights }
			\STATE { $h$ = weak classifiers}
			\STATE {$I$ = image}
			\STATE {$p$ = prediction} 
			\FOR {$t=1$ to $length(\alpha)$}
				\STATE $p \leftarrow p + \alpha_th_t(I)$
			\ENDFOR
			\STATE {\tbf{return} $sign(p)$}
			\end{algorithmic}
			\label{alg:AdaBoostPredict}
		\end{algorithm}
	\section{Results}\label{sec:results}
	\hspace*{10px}The available image set was spilt into a holdout set and the rest of the data was again split into a validation set and a part that was used for training the final model by \emph{random sub-sampling cross-validation} technique. The whole process of defining the validation set and applying random sub-sampling cross-validation was repeated several times to ensure a correct estimation of the predictions. For each round of the cross-validation, a model was trained using the \emph{AdaBoost algorithm} described above. The obtained model was, then, tested by building the strong classifier and computing the corresponding values for: \emph{true-positive estimation}, \emph{true-negative estimation}, \emph{false-positive estimation} and \emph{false-negative estimation}.\\
	\subsection{Convolution Results}\label{sec:haar_results}
	\hspace*{10px}Due to the fact that the number of features generated for only 21 patterns and a segmentation for each image of 23 overlapping regions by 9 gives 4,347 features, the training part is relatively slow for this method. In order to create reliable model we have used 5 repetitions, 10 hypothesis (features to be chosen by AdaBoost), 10 trials in the random sampling cross-validation method.\\
	\hspace*{10px}In Figure\ref{haar_regions10} are indicated the most voted regions for the 10 Euro bills in \emph{AdaBoost} throughout all trials and all repetitions. We can notice that for the front of the bills the regions selected are mainly positions on the water mark area, while for the rear side of the bills, there are some regions considered as being the most informative on the white patch, but also the area in the middle is selected as containing discriminative information.\\  
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/haar_regions10.eps, width=1\linewidth}
\caption{Best regions for 10 Euro bills}
\label{haar_regions10}
\end{figure}
	\hspace*{10px}Figure\ref{haar_regions5} shows the most voted regions for the 5 Euro bills in \emph{AdaBoost} throughout all trials and all repetitions. For the 5 Euro bills the regions for front and rear that were chosen as being the most informative ones are again mainly around the water mark area, but unlike those for 10 Euro Bills, the regions for front side are the ones that are more spread throughout the image.\\  
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/haar_regions5.eps, width=1\linewidth}
\caption{Best regions for 5 Euro bills}
\label{haar_regions5}
\end{figure} 
	\hspace*{10px}In order to determine the optimal number of features that should be chosen in the end for the best model, we have plotted the error with respect to the number of features chosen. Figure\ref{haar_plot10} and Figure\ref{haar_plot5} show how the error evolves depending on the number of models for the 10 Euro bills, respectively for the 5 Euro bills.
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/haar_plot10.eps, width=1\linewidth}
\caption{Error depending on the number of features - 10 Euro bills}
\label{haar_plot10}
\end{figure} 
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/haar_plot5.eps, width=1\linewidth}
\caption{Error depending on the number of features - 5 Euro bills}
\label{haar_plot5}
\end{figure} 
	\subsection{PCA Results}\label{sec:pca_results}
	\todo{RESULTS PCA}

	\subsection{Intensity \& Edges Results}\label{sec:ie_results}
	\todo{RESULTS IE}

	\subsection{Combined Results}\label{sec:comb_results}
	\hspace*{10px}Once all the strong classifiers for each of the methods above has been generated, we have combined their predictions using \emph{Naive Bayes}.\\
	\hspace*{10px}The results for 10 Euro bills, respectively 5 Euro bills are shown in the Table\ref{table10} and Table\ref{table5}.
		\begin{table}[!htbp]
			\caption{Results for 10 Euro bills}
			\fontfamily{ccr}\selectfont\small
			\label{table10}
			\centering 
			\begin{tabular}{ | c | c | c|}
				\hline\hline & \emph{Fit Error} & \emph{Unfit Error} \\ [0.5ex]\hline 
				\emph{Haar} & 0.05 & 0.15 \\ [0.5ex]\hline
				\emph{IE} & 0.1 & 0.025 \\ [0.5ex]\hline
				\emph{PCA} & 0.083 & 0.05 \\ [0.5ex]\hline
				\emph{Haar \& IE} & 0.033 & 0.15 \\ [0.5ex]\hline
				\emph{Haar \& PCA} & 0.017 & 0.2 \\ [0.5ex]\hline
				\emph{IE \& PCA} & 0.017 & 0.075 \\ [0.5ex]\hline
				\emph{Haar \& IE \& PCA} & 0.033 & 0.025 \\ [0.5ex]\hline
			\end{tabular}
			\label{table:nonlin} 
		\end{table}		
		\begin{table}[!htbp]
			\caption{Results for 5 Euro bills}
			\fontfamily{ccr}\selectfont\small
			\label{table5}
			\centering 
			\begin{tabular}{ | c | c | c|}
				\hline\hline & \emph{Fit Error} & \emph{Unfit Error} \\ [0.5ex]\hline 
				\emph{Haar} & 0 & 0 \\ [0.5ex]\hline
				\emph{IE} & 0.033 & 0 \\ [0.5ex]\hline
				\emph{PCA} & 0.083 & 0.025 \\ [0.5ex]\hline
				\emph{Haar \& IE} & 0 & 0 \\ [0.5ex]\hline
				\emph{Haar \& PCA} & 0 & 0.025 \\ [0.5ex]\hline
				\emph{IE \& PCA} & 0.033 & 0.025 \\ [0.5ex]\hline
				\emph{Haar \& IE \& PCA} & 0.033 & 0 \\ [0.5ex]\hline
			\end{tabular}
			\label{table:nonlin} 
		\end{table}		  	
	\section{Conclusion}\label{sec:conclusion}
		\hspace*{10px}From our experiments we have been able to learn the regions that contain the largest amount of information and help us distinguish between fit and unfit bills. These regions differ from one method to another, but in general the areas around the water-mark region and the middle of the bills have been proven to be the ones containing the most discriminative features.\\
		\hspace*{10px}As it can be noticed from the results in Section\ref{sec:comb_results}, combining different techniques leads to an improvement in the performance of the final classifier.\\
		\hspace*{10px}Although the results obtained using these 3 methods are as good as we would have expected them to be, future work is possible and it should be mainly focused on finding a more powerful way of combining all the features used by all 3 techniques (Haar, PCA, Intensity \& Edge) into a strong classifier.\\
		\hspace*{10px}We would also recommend that special attention should be payed to the validity of certain features of the images from the data set (intensity).\\  
	\begin{thebibliography}{2} 
		\bibitem{Haar}
			P. Viola \& M. Jones:\\
			\tit{Rapid Object Detection using a Boosted Cascade of Simple Features}
			(CVPR 2001)
		\bibitem{Ada}
			AdaBoost: \\
			\tit{http://en.wikipedia.org/wiki/AdaBoost}	
	\end{thebibliography}

\end{document}
