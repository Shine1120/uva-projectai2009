\documentclass[11pt,twocolumn]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{color}
\usepackage{epsfig}
\usepackage{float}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{float}
\setlength\topmargin{-0.5in}
\setlength\headsep{0in}
\setlength\textheight{9.5in}
\definecolor{gray}{rgb}{0.9,0.9,0.9}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\tbf}{\textbf}
\newcommand{\tit}{\textit}
\newcommand{\ds}{\displaystyle}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

\title{\tbf{Dirty Money:}\\\tbf{Feature selection using AdaBoost}}
\author{J. van Turnhout (0312649) jturnhou@science.uva.nl, \\ N. Raiman (0336696) nraiman@science.uva.nl, \\ S. L. Pintea (6109969) s.l.pintea@student.uva.nl}

\begin{document}
	\maketitle
	\begin{abstract}
	\hspace*{10px}In the month January of 2010 a project on the classification of the fitness of money was proposed. During this month we have tested and implemented various techniques to handle the problem of money classification. The results from our experiment show promising development comparing to the current state of research.\\
	\hspace*{10px}In the below sections we have described the approaches that we have tried and the results obtained for each one of them.
	\end{abstract}
	\section{Introduction}
	\hspace*{10px}The goal of this project is to determine a reliable method that would be able to distinguish between dirty bills and clean bills. In order to achieve this goal we had to think of what are the representative features of dirt that can be found on money bills and what is the best method that can be used to model this.\\ 
	\hspace*{10px}Throughout this project we have tried a number of different approaches in order to gain good results and in the same time we have tried to get a better understanding of what methods are fit for describing the features of the dirty money and clean money.\\
	\hspace*{10px}The main techniques used in this project are: \emph{PCA} in combination with \emph{AdaBoost}, \emph{Haar-like features} and \emph{Adaboost}, \emph{Convolution with predefined kernels}, \emph{edge-detection} and \emph{intensity} distributions.\\
	\hspace*{10px}In section \ref{sec:background}, related work on \emph{Haar-like features}, \emph{convolution with kernels}, \emph{PCA}, \emph{SVM}, \emph{AdaBoost}, \emph{edge detection} and \emph{intensity} are discussed. The implementation of the \emph{AdaBoost} algorithm applied on the different techniques is explained in \ref{sec:implementation}. We discuss our experiments and their results in section \ref{sec:results}. Finally, we conclude in section \ref{sec:conclusion} and propose some topics for future research.
	\section{Background}\label{sec:background}
	\hspace*{10px}Finding the main features of dirty money and clean money was a true challenge in this project. In this section are indicated in more detail the ups and downs of the techniques used and the theoretical knowledge that represents the basis of these methods.
	\subsection{PCA and Adaboost}\label{sec:PCA}
	\hspace*{10px}The \emph{AdaBoost} algorithm is used in combination with different techniques throughout this project, such as: \emph{PCA}, \emph{Haar-like features} or \emph{edge} and \emph{intensity} distributions over different regions.\\
		\hspace*{10px}Adaptive Boosting (also known as AdaBoost) is a machine learning technique which can be used in conjunction with various other learning algorithms. The idea is to have a (convex) set of weak classifiers (classifiers that perform at least better than random) and then minimize the total error over the training-set by finding the best classifier at each stage of the algorithm.\\
		\hspace*{10px}The theoretical basis of this algorithm is that given a set of models (or features), \emph{M}, the algorithm will determine the subset of \emph{T} models that are the best for distinguishing between the two classes (fit and unfit bills). Thus, \emph{AdaBoost} will learn the most representative features of the two classes. The algorithm for determining the best models is shown in section \ref{sec:implementation}: \emph{Algorithm~\ref{AdaBoost}}.\\
		\hspace*{10px}Another very important characteristic of this algorithm is the fact that it also specifies a method in which the models that were chosen as being the best, can be combined in order to give a strong classifier. The corresponding algorithm can be seen in section \ref{sec:implementation}: \emph{Algorithm~\ref{AdaBoost_pred}}.\\
		\todo{\hspace*{10px}PCA !!!}
	\subsection{Intensity and Edge distributions}\label{sec:Intensity_Edge}
		\todo{\hspace*{10px}Intensity \& Edge!!!\\}
	\subsection{Haar-like features and Convolution over kernels}\label{sec:Haar}
	\hspace*{10px}The first idea that we have tried was to implement the \emph{Viola \& Jones} approach for object detection. The final cascade used in this paper was not implemented because the main idea of this cascade was not suitable for the purpose of this project. We have used the strong classifier computed in \emph{AdaBoost} as the final output.\\
\begin{figure}[!hbtp]
\fbox{
	\epsfig{file=img/patterns.eps, width=0.9\linewidth}
}	
\caption{Patterns}
\label{patterns}
\end{figure}
	\hspace*{10px}The first step of the algorithm is defining the patterns, that are mainly matrixes of different dimensions containing low and high values for intensity (-1 and 1) -- Figure\ref{patterns} indicates a subset of the patterns used. The algorithm used in the \emph{Viola \& Jones} article was designed to loop over all predefined patterns on each position in the image and convolve the specific region of the image with the patterns using the formula:
\begin{figure}
\fontfamily{ccr}\selectfont\small
\begin{tabular}{|lr|} \hline
	& \\[5pt]
	\textcolor{blue}{$Value = \sum_x\sum_y Image(y:y+h,x:x+w) .* Pattern$}, &\\[10pt]
	where: \emph{h} -- the heigh of the pattern &\\
	\hspace*{28px} \emph{w} -- the width of the pattern &\\[5pt] 
\hline 
\end{tabular}

\end{figure}
\hspace*{10px}We have started by defining a large number of patterns of different sizes ($\approx$100 patterns), and we have filtered out those that gave bad results when used in the \emph{AdaBoost algorithm} for training the weak classifiers.\\ 
The resulted values for each pattern and location in the image would, then, be used in \emph{AdaBoost} to train an \emph{SVM} classifier. Taking into account the fact that the set of features generated by the algorithm for each pattern and each image, was extremely large, and the training took too much time. In order to solve this problem, we have decided to use just random locations at which to convolve the patterns with a region of the image (that would have the same size with the pattern). Figure~\ref{Haar_features} indicates what \emph{AdaBoost} would choose as being the most representative 5 features for the front side and rear side of the bills.\\
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/haar.eps, width=1\linewidth}
\caption{Haar Features for Front and Rear}
\label{Haar_features}
\end{figure}
	\hspace*{10px}The results obtained using \emph{Haar features} were not as good as we would have expected them to be. An explanation for this may be the fact that the patterns defined were not entirely able to model the dirt that can be found on the bills.\\
	\hspace*{10px}The second approach that we have tried was to define a set of patterns as before, and to segment each image into smaller regions that would be, then, convolved with the patterns.\\
	\hspace*{10px}We have tried using both no-overlapping segmentation of the images and 50\% overlapping one. Due to the fact that many essential pixel values (like those that would indicate the presence of dirt) may happen to be positioned on the line that separates two neighboring regions, is possible that some information will be lost. Taking into account the number of regions generated for all images we can notice that there is a large amount of pixel values that might not be considered in the case of no-overlapping segmentation. As expected, the second method of dividing the images into regions gave better results compared to the first one.\\ 
	\hspace*{10px}The results obtained using this technique represented the input set of features for the \emph{AdaBoost algorithm}. Figure~\ref{convolved} will help getting a better understanding of how the convolved regions of image and patterns would look like. In this image it is plotted the result obtained when convolving a bill with a simple pattern such as: \textbf{[1 -1;-1 1]} with an entire bill.\\
\begin{figure}[!hbtp]
\centering
\epsfig{file=img/convolution.eps, width=1\linewidth}
\caption{Convolution of an entire bill}
\label{convolved}
\end{figure} 
Thus, the resulted set of models would represent the input features used in \emph{AdaBoost}. For establishing the set of the best \emph{T} features we have tried using both \emph{SVM} and \emph{Gaussian distribution}, and the results retrieved by the last one seemed slightly better than the ones obtained while using \emph{SVM}. In the case in which \emph{SVM} was used, a model was generated for each available feature. This model would give the best separation between the values corresponding to that feature for fit images and those for unfit images. In the case of the \emph{Gaussian distribution}, the mean and covariance of features corresponding to fit images were computed, respectively the mean and covariance for the features corresponding to unfit images. In order to determine the predicted class of the input images we have tried two methods:
\begin{itemize}
\item In the first method we would simply compute the \emph{mean} and \emph{covariance} for the values corresponding to fit, respectively unfit values corresponding to a specific feature. During testing, for each input value, we would compare the two numbers returned by \emph{Gaussian density function} for fit, respectively unfit and we would choose the predicted class to be the maximum of the two  
\item The second method was using \emph{Naive Bayes} in order to make use of the prior knowledge available. We know that in a real-life situation there are always more fit bills than unfit one and we would like to use this information to improve our classifiers. The predicted class was defined by using the \emph{MAP} (maximum aposterior probability) estimation. The formula for computing the maximum aposterior probability for fit, respectively unfit class is given by:
\begin{figure}
	\fontfamily{ccr}\selectfont\small
	\begin{tabular}{|lr|} \hline
		&\\[5pt]
		\textcolor{blue}{$argmax_{\theta_{fit}}P(\theta_{fit}\mid X) = $} &\\[3pt]
		\hspace*{70px}\textcolor{blue}{$\frac{P(\theta_{fit})*P(X\mid \theta_{fit})}{P(\theta_{fit})*P(X\mid \theta_{fit}) + P(\theta_{unfit})*P(X\mid \theta_{unfit})}$} &\\[10pt]
		\textcolor{blue}{$argmax_{\theta_{unfit}}P(\theta_{fit}\mid X) = $} &\\[3pt]
		\hspace*{70px}\textcolor{blue}{$\frac{P(\theta_{unfit})*P(X\mid \theta_{unfit})}{P(\theta_{fit})*P(X\mid \theta_{fit}) + P(\theta_{unfit})*P(X\mid \theta_{unfit})}$} &\\[10pt]
\hline
\end{tabular}
		where: 
		\begin{itemize}
		\item $P(\theta_{fit}), P(\theta_{unfit})$ -- marginal probabilities of "fit" class, respectively "unfit" class 
		\item $\theta_{fit}, \theta_{unfit}$ -- the parameters of the classes (mean and covariance) 
		\item $P(X\mid \theta_{fit}),P(X\mid \theta_{unfit})$ -- the conditional probabilities of the two classes (representing normal distributions) 
		\end{itemize} 
\end{figure}

It can be easily shown that the values of the parameters $\theta$ for a normal distribution (mean and covariance) that would maximize the probability of the classes are exactly the corresponding formulas: 
\emph{
\begin{figure}
\fontfamily{ccr}\selectfont\small
\begin{tabular}{|lr|} \hline
		&\\[5pt]	
		\textcolor{blue}{$\mu$ = $\sum_i \frac{x_i}{\mid X \mid}$} &\\
		\textcolor{blue}{$\sigma$ = $\frac{(X - \mu)(X - \mu)^T}{\mid X \mid}$} &\\[10pt]  
		where X -- the training data set &\\
		\hspace*{28px} $\mu$ -- the mean &\\
		\hspace*{28px} $\sigma$ -- the covariance &\\[5pt]
\hline
\end{tabular}
\end{figure}
}\end{itemize}
The second technique used for determining the predicted class of the data given the parameters seemed to provides slightly better results in practice due to the fact that it also incorporates some prior knowledge of the data.\\  
 		\hspace*{10px}For this approach we have used two classifiers: one for the rear side and another for the front side of the bills and the predictions given by the two classifiers were combined into a third one using Naive Bayes.\\
		\hspace*{10px}In order to create the final model, we have tried two different methods: 
\begin{itemize}
\item the first one was essentially just choosing the best model (the one that gives the minimum error) throughout all the repetitions and all the rounds in the cross-validation;
\item the second method was to use a system of voting -- each time a feature was chosen by the \emph{AdaBoost} algorithm, it would receive a vote. In the end the top \emph{T} most voted features throughout all the cross-validation rounds and all the repetitions would be chosen from the best model found. The corresponding weights would be generate by taking the mean of the features\rq\@ $\alpha$-weights computed in the \emph{AdaBoost} algorithm;     
\end{itemize}
As we would have expected, the second method for defining the best model, proved to give better results in this case so it was chosen to be applied.\\
\section{Implementation}\label{sec:implementation}
		\begin{algorithm}[!hbtp]
			\caption{AdaBoost learning features}
			\label{AdaBoost}
			\begin{algorithmic}[1]
			\medskip
			\STATE \tbf{function} AdaBoostLearn($T$, $M$, $S$) 
			\STATE {$T$ = nr. of hypothesis}
			\STATE {$M$ = Models}
			\STATE {$S$ = training-set, \{$(x_1,y_1),...(x_n,y_n)$\} \\ with $x_i \epsilon X$ and $y_i \epsilon \{-1, 1\}$ }
			\STATE {$D_{1(i)} \leftarrow \frac{1}{n}$, with $i=1,...,n$}
			\FOR {$t=1$ to $T$}
				\STATE {$error_t \leftarrow 0$}
				\FOR {$m \epsilon M$}
					\STATE {$h_j(x_i) \leftarrow predict(x_i)$ \%\tit{svm or gaussian distribution}}
					\STATE {$error_j \leftarrow \sum^n_{i=1}D_t(i)[y_i \neq h_j(x_i)]$}
					\IF {$error_j < error_t$}
						\STATE {$error_t \leftarrow error_j$}
						\STATE {$h_t \leftarrow h_j$}
					\ENDIF
				\ENDFOR
				\STATE {$\alpha_t \leftarrow 0.5 \cdot \log{\frac{1-error_t}{error_t}}$}
				\FOR {$i=1$ to $n$}
					\STATE {$D_{t+1}(i) \leftarrow \frac{D_t(i)\exp{-\alpha_t \cdot y_i \cdot h_t(x_i)}}{Z_t}$}
				\ENDFOR
			\ENDFOR
			\STATE {\tbf{return} $\alpha, h$}
			\end{algorithmic}
			\label{alg:AdaBoostLearn}
		\end{algorithm}
		\begin{algorithm}[!hbtp]
			\caption{AdaBoost Prediction}
			\label{AdaBoost_pred}
			\begin{algorithmic}[1]
			\medskip
			\STATE \tbf{function} AdaBoostPredict($\alpha$, $h$, $I$)
			\STATE { $\alpha$ = weights }
			\STATE { $h$ = weak classifiers}
			\STATE {$I$ = image}
			\STATE {$p$ = prediction} 
			\FOR {$t=1$ to $length(\alpha)$}
				\STATE $p \leftarrow p + \alpha_th_t(I)$
			\ENDFOR
			\STATE {\tbf{return} $sign(p)$}
			\end{algorithmic}
			\label{alg:AdaBoostPredict}
		\end{algorithm}

	\section{Results}\label{sec:results}
	\hspace*{10px}The available image set was spilt into a holdout set and the rest of the data was again split into a validation set and a part that was used for training the final model by \emph{random sub-sampling cross-validation} technique. The whole process of defining the validation set and applying random sub-sampling cross-validation was repeated several times to ensure a correct estimation of the predictions. For each round of the cross-validation, a model was trained using the \emph{AdaBoost algorithm} described above. The obtained model was, then, tested by building the strong classifier and computing the corresponding values for: \emph{true-positive estimation}, \emph{true-negative estimation}, \emph{false-positive estimation} and \emph{false-negative estimation}.\\ 
	\subsection{Convolution Results}\label{sec:haar_results}
	\hspace*{10px}Due to the fact that the number of features generated for only 21 patterns and a segmentation of 12 regions by 5 of the image gives 1,260 features\todo{???!!!}, the training part is relatively slow for this method. In order to create reliable model we have used 5 repetitions, 10 hypothesis (features to be chosen by AdaBoost), 10 trials in the random sampling cross-validation method.\\

	\subsection{Convolution Results}\label{sec:pca_results}
	\todo{RESULTS PCA}
	\subsection{Convolution Results}\label{sec:ie_results}
	\todo{RESULTS IE}

	\section{Conclusion}\label{sec:conclusion}
	\begin{thebibliography}{2}
		\bibitem{Haar}
			P. Viola \& M. Jones:\\
			\tit{Rapid Object Detection using a Boosted Cascade of Simple Features}
			(CVPR 2001)
		\bibitem{Ada}
			AdaBoost: \\
			\tit{http://en.wikipedia.org/wiki/AdaBoost}	
	\end{thebibliography}

\end{document}
